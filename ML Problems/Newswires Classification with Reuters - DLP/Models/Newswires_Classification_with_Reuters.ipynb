{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Newswires Classification with Reuters.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPY2dEf2BM3JjZ/DFipSfuc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keivanipchihagh/Intro_To_MachineLearning/blob/master/Models/Newswires_Classification_with_Reuters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riErnUwfLKDw"
      },
      "source": [
        "# Newswires Classification with Reuters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5T_EHZXNShT"
      },
      "source": [
        "##### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UdxYS9ALHTE"
      },
      "source": [
        "import numpy as np                                # Numpy\n",
        "from matplotlib import pyplot as plt              # Matplotlib\n",
        "import keras                                      # Keras\n",
        "import pandas as pd                               # Pandas\n",
        "from keras.datasets import reuters                # Reuters Dataset\n",
        "from keras.utils.np_utils import to_categorical   # Categirical Classifier\n",
        "import random                                     # Random"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ptvrGNGNpoD"
      },
      "source": [
        "##### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFnLXk66NryE"
      },
      "source": [
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words = 10000)\n",
        "print('Size:', len(train_data))\n",
        "print('Training Data:', train_data[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBtaode-Tu1_"
      },
      "source": [
        "##### Get the feel of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAg-wM4ITxA6"
      },
      "source": [
        "def decode(index):  # Decoding the sequential integers into the corresponding words\n",
        "  word_index = reuters.get_word_index()\n",
        "  reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "  decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in test_data[0]])\n",
        "  return decoded_newswire\n",
        "\n",
        "print(\"Decoded test data sample [0]: \", decode(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGUDyWwXTpar"
      },
      "source": [
        "##### Data Prep (One-Hot Encoding)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl3MVkNxTsU0"
      },
      "source": [
        "def vectorize_sequences(sequences, dimension = 10000):    # Encoding the integer sequences into a binary matrix\n",
        "  results = np.zeros((len(sequences), dimension))\n",
        "  for i, sequence in enumerate(sequences):\n",
        "    results[i, sequence] = 1.\n",
        "  return results\n",
        "\n",
        "train_data = vectorize_sequences(train_data)\n",
        "test_data = vectorize_sequences(test_data)\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0AS2vWYT9au"
      },
      "source": [
        "##### Building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JUWJ32YT_iy"
      },
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(units = 64, activation = 'relu', input_shape = (10000,)))\n",
        "model.add(keras.layers.Dense(units = 64, activation = 'relu'))\n",
        "model.add(keras.layers.Dense(units = 46, activation = 'softmax'))\n",
        "model.compile( optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7_1oOMZUeur"
      },
      "source": [
        "##### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8y3-hzfUhQS"
      },
      "source": [
        "x_val = train_data[:1000]\n",
        "train_data = train_data[1000:]\n",
        "y_val = train_labels[:1000]\n",
        "train_labels = train_labels[1000:]\n",
        "\n",
        "history = model.fit(train_data, train_labels, batch_size = 512, epochs = 10, validation_data = (x_val, y_val), verbose = False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jO0xF9RMVILe"
      },
      "source": [
        "##### Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy2nZqQyVKJU"
      },
      "source": [
        "result = model.evaluate(train_data, train_labels)\n",
        "print('Loss:', result[0])\n",
        "print('Accuracy:', result[1] * 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo60EKVGVZbM"
      },
      "source": [
        "##### Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQhxXomBVa3P"
      },
      "source": [
        "epochs = range(1, len(history.history['loss']) + 1)\n",
        "plt.plot(epochs, history.history['loss'], 'b', label = 'Training Loss')\n",
        "plt.plot(epochs, history.history['val_loss'], 'r', label = 'Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.clf()\n",
        "plt.plot(epochs, history.history['accuracy'], 'b', label = 'Training Accuracy')\n",
        "plt.plot(epochs, history.history['val_accuracy'], 'r', label = 'Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uvoc0-o6WQxC"
      },
      "source": [
        "##### Making predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z360IVlBWSKt"
      },
      "source": [
        "prediction_index = random.randint(0, len(test_data))\n",
        "prediction_data = test_data[prediction_index]\n",
        "decoded_prediction_data = decode(prediction_index)\n",
        "\n",
        "# Info\n",
        "print('Random prediction index:', prediction_index)\n",
        "print('Original prediction Data:', prediction_data)\n",
        "print('Decoded prediction Data:', decoded_prediction_data)\n",
        "print('Expected prediction label:', np.argmax(test_labels[prediction_index]))\n",
        "\n",
        "# Prediction\n",
        "predictions = model.predict(test_data)\n",
        "print('Prediction index: ', np.argmax(predictions[prediction_index]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}