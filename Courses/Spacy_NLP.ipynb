{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NukeLab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hn8dk326QMFH"
      },
      "source": [
        "# Sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsKX6vjpQO5G"
      },
      "source": [
        "## Count Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I__iPA_NQIu2",
        "outputId": "9876f079-55e8-46d5-db88-11257b10c07b"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "class Category:\n",
        "  BOOKS = 'BOOKS'\n",
        "  CLOTHING = 'CLOTHING'\n",
        "\n",
        "X_train = [\n",
        "      'i love the book',\n",
        "      'this is a great book',\n",
        "      'the fit is great',\n",
        "      'i love the shoes'\n",
        "]\n",
        "\n",
        "y_train = [\n",
        "      Category.BOOKS,\n",
        "      Category.BOOKS,\n",
        "      Category.CLOTHING,\n",
        "      Category.CLOTHING,\n",
        "]\n",
        "\n",
        "X_test = [\n",
        "      'i like the book',\n",
        "      'you should ware warm clothes',\n",
        "      'say you read a novel'\n",
        "]\n",
        "\n",
        "count_vect = CountVectorizer(\n",
        "    lowercase = True,\n",
        "    # stop_words = 'english',\n",
        "    analyzer = 'word',\n",
        "    # ngram_range = (1, 3)\n",
        "    binary = True\n",
        ")\n",
        "\n",
        "X_train_count_vect = count_vect.fit_transform(X_train)\n",
        "X_test_count_vect = count_vect.transform(X_test)\n",
        "\n",
        "print(count_vect.get_feature_names())\n",
        "print(X_train_count_vect.toarray())\n",
        "\n",
        "print('SVC:', svc_model(X_train_count_vect, y_train, X_test_count_vect))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "['book', 'fit', 'great', 'is', 'love', 'shoes', 'the', 'this']\n",
            "[[1 0 0 0 1 0 1 0]\n",
            " [1 0 1 1 0 0 0 1]\n",
            " [0 1 1 1 0 0 1 0]\n",
            " [0 0 0 0 1 1 1 0]]\n",
            "SVC: ['BOOKS' 'CLOTHING' 'CLOTHING']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNATIyW0VWey"
      },
      "source": [
        "## TFIDf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wx4z7sxPVY5e",
        "outputId": "f1b0655a-c482-4e46-8a82-1a9bc6ff0892"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vect = TfidfVectorizer()\n",
        "\n",
        "X_tfidf_vect = tfidf_vect.fit_transform(X_train)\n",
        "\n",
        "X_train_tfidf_vect = tfidf_vect.fit_transform(X_train)\n",
        "X_test_tfidf_vect = tfidf_vect.transform(X_test)\n",
        "\n",
        "print(tfidf_vect.get_feature_names())\n",
        "print(X_tfidf_vect.toarray())\n",
        "\n",
        "print('SVC:', svc_model(X_train_count_vect, y_train, X_test_count_vect))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['book', 'fit', 'great', 'is', 'love', 'shoes', 'the', 'this']\n",
            "[[0.61366674 0.         0.         0.         0.61366674 0.\n",
            "  0.49681612 0.        ]\n",
            " [0.46580855 0.         0.46580855 0.46580855 0.         0.\n",
            "  0.         0.59081908]\n",
            " [0.         0.61422608 0.4842629  0.4842629  0.         0.\n",
            "  0.39205255 0.        ]\n",
            " [0.         0.         0.         0.         0.55349232 0.70203482\n",
            "  0.44809973 0.        ]]\n",
            "SVC: ['BOOKS' 'CLOTHING' 'CLOTHING']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4koOKbRs8gac"
      },
      "source": [
        "# Spacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ElsbQ3N8hdK",
        "outputId": "7b14a08a-3152-4978-9b75-20fea57e4547"
      },
      "source": [
        "from spacy.lang.en import English\n",
        "\n",
        "nlp = English()\n",
        "\n",
        "doc = nlp('Hello World!')\n",
        "\n",
        "for token in doc:\n",
        "  print(token, end = ', ')\n",
        "\n",
        "token = doc[1]\n",
        "\n",
        "print(token.text)\n",
        "\n",
        "span = doc[1:3]\n",
        "\n",
        "print(span.text)\n",
        "\n",
        "doc = nlp('It costs $5.')\n",
        "\n",
        "print('Index:', [token.i for token in doc])\n",
        "print('Text:', [token for token in doc])\n",
        "print('Is Puntuation:', [token.is_punct for token in doc])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello, World, !, World\n",
            "World!\n",
            "Index: [0, 1, 2, 3, 4]\n",
            "Text: [It, costs, $, 5, .]\n",
            "Is Puntuation: [False, False, False, False, True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgOjpGb2ArqW",
        "outputId": "7525eded-ae94-40b4-9110-d90aad02dfe2"
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "doc = nlp('She ate the pizza')\n",
        "\n",
        "for token in doc:\n",
        "  print(token.text, token.pos_, token.dep_, token.head.text, sep = '\\t')\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, ent.label_, sep = '\\t')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "She\tPRON\tnsubj\tate\n",
            "ate\tVERB\tROOT\tate\n",
            "the\tDET\tdet\tpizza\n",
            "pizza\tNOUN\tdobj\tate\n",
            "\n",
            "\n",
            "Apple\tORG\n",
            "U.K.\tGPE\n",
            "$1 billion\tMONEY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HbGtq9eD1lR",
        "outputId": "d73ba3ab-eed3-4429-b690-784238b516cf"
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "text = 'Nearly 40% of Marines have declined Covid-19 vaccine'\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, ent.label_)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nearly 40% PERCENT\n",
            "Marines ORG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbMIQ3Qga1Bf",
        "outputId": "bc4b5f14-3ebb-454d-c1e2-74fc7799e770"
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "text = 'Apple is looking forward buying U.K. startup for $2 Billion.'\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "for token in doc:\n",
        "  print(token.text, token.lemma, token.pos_, token.tag_, token.dep_, token.shape_, token.is_alpha, token.is_stop, sep = '\\t')\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, ent.start_char, ent.end_char, ent.label_, sep = '\\t')\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "for token in doc:\n",
        "    print(token.text, token.has_vector, token.vector_norm, token.is_oov, sep = '\\t')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple\t6418411030699964375\tPROPN\tNNP\tnsubj\tXxxxx\tTrue\tFalse\n",
            "is\t10382539506755952630\tAUX\tVBZ\taux\txx\tTrue\tTrue\n",
            "looking\t16096726548953279178\tVERB\tVBG\tROOT\txxxx\tTrue\tFalse\n",
            "forward\t17319973514577326793\tADV\tRB\tadvmod\txxxx\tTrue\tFalse\n",
            "buying\t9457496526477982497\tVERB\tVBG\tadvcl\txxxx\tTrue\tFalse\n",
            "U.K.\t14409890634315022856\tPROPN\tNNP\tcompound\tX.X.\tFalse\tFalse\n",
            "startup\t7622488711881293715\tNOUN\tNN\tdobj\txxxx\tTrue\tFalse\n",
            "for\t16037325823156266367\tADP\tIN\tprep\txxx\tTrue\tTrue\n",
            "$\t11283501755624150392\tSYM\t$\tquantmod\t$\tFalse\tFalse\n",
            "2\t15180167692696242062\tNUM\tCD\tcompound\td\tFalse\tFalse\n",
            "Billion\t1231493654637052630\tNUM\tCD\tpobj\tXxxxx\tTrue\tFalse\n",
            ".\t12646065887601541794\tPUNCT\t.\tpunct\t.\tFalse\tFalse\n",
            "\n",
            "\n",
            "Apple\t0\t5\tORG\n",
            "U.K.\t32\t36\tGPE\n",
            "$2 Billion\t49\t59\tMONEY\n",
            "\n",
            "\n",
            "Apple\tTrue\t21.877224\tTrue\n",
            "is\tTrue\t23.891558\tTrue\n",
            "looking\tTrue\t24.650583\tTrue\n",
            "forward\tTrue\t22.551302\tTrue\n",
            "buying\tTrue\t20.931828\tTrue\n",
            "U.K.\tTrue\t22.256153\tTrue\n",
            "startup\tTrue\t20.861286\tTrue\n",
            "for\tTrue\t21.47685\tTrue\n",
            "$\tTrue\t21.279455\tTrue\n",
            "2\tTrue\t22.103958\tTrue\n",
            "Billion\tTrue\t21.820871\tTrue\n",
            ".\tTrue\t21.885965\tTrue\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFfmYxykUwHO"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAcTF54mUxDG"
      },
      "source": [
        "## SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpjVio3rTYmT"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "def svc_model(X_train, y_train, X_test):\n",
        "\n",
        "  svc = SVC()\n",
        "  svc.fit(X_train, y_train)\n",
        "  return svc.predict(X_test)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DQ8cc-zU21K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}