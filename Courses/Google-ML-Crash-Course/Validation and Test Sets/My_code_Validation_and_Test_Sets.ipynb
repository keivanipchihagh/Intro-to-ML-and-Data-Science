{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "My code - Validation and Test Sets.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPo45e4hqRmaIrr2SiuZYlQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keivanipchihagh/Google-ML-Crash-Course/blob/master/Validation%20and%20Test%20Sets/My_code_Validation_and_Test_Sets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHqEbxElVPtv",
        "cellView": "form"
      },
      "source": [
        "#@title Import modules\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCY5VoZGVmsy",
        "cellView": "both"
      },
      "source": [
        "# Load datasets\n",
        "train_data = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\")\n",
        "test_data = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv\")\n",
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hL5qt5JNV3Ee"
      },
      "source": [
        "# Scale\n",
        "scale_factor = 1000.0\n",
        "\n",
        "train_data['median_house_value'] /= scale_factor\n",
        "test_data['median_house_value'] /= scale_factor\n",
        "\n",
        "# Shuffle\n",
        "train_data = train_data.reindex(np.random.permutation(train_data.index))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mKqrClqWnk0"
      },
      "source": [
        "# Build the model\n",
        "def build_model(learning_rate):\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(units = 1, input_shape = (1,)))\n",
        "  \n",
        "  model.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate = learning_rate), \n",
        "                loss = tf.keras.losses.mean_absolute_error, \n",
        "                metrics = [tf.keras.metrics.RootMeanSquaredError()])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xy07AoGKXY0K"
      },
      "source": [
        "# Train the model\n",
        "def train_model(model, dataframe, feature, label, epochs, verbose, batch_size = None, validation_split = 0.1):\n",
        "  history = model.fit(x = dataframe[feature], \n",
        "                      y = dataframe[label], \n",
        "                      batch_size = batch_size, \n",
        "                      epochs = epochs, \n",
        "                      validation_split = validation_split, \n",
        "                      verbose = verbose)\n",
        "\n",
        "  return history.epoch, pd.DataFrame(history.history)[\"root_mean_squared_error\"], history.history   "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgO1HAbsYV0d"
      },
      "source": [
        "# Plot the statistics\n",
        "def plot(epochs, training, validation):\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Root Mean Squared Error\")\n",
        "\n",
        "  plt.plot(epochs[1:], training[1:], label=\"Training Loss\")\n",
        "  plt.plot(epochs[1:], validation[1:], label=\"Validation Loss\")\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov8F4lg2h8e-"
      },
      "source": [
        "# Summon up\n",
        "learning_rate = 0.08\n",
        "epochs = 30\n",
        "batch_size = 100\n",
        "validation_split = 0.1\n",
        "feature=\"median_income\"\n",
        "label=\"median_house_value\"\n",
        "verbose = False\n",
        "\n",
        "model = build_model(learning_rate)\n",
        "epoch, rmse, history = train_model(model, train_data, feature, label, epochs, verbose, batch_size, validation_split)\n",
        "print(history.keys())\n",
        "plot(epoch, history['root_mean_squared_error'], history['val_root_mean_squared_error'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lfi5vTevnOR-"
      },
      "source": [
        "# Evaluate\n",
        "results = model.evaluate(x = test_data[feature], y = test_data[label], batch_size = batch_size)\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}