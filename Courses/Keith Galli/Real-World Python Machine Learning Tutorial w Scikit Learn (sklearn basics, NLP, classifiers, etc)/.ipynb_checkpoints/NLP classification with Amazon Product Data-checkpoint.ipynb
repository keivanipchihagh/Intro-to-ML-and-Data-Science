{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "biological-drill",
   "metadata": {},
   "source": [
    "# NLP classification with Amazon Product Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-davis",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "colored-casino",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "# sklearn libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-tattoo",
   "metadata": {},
   "source": [
    "## Data Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "personalized-colonial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Enum\n",
    "class Sentiment:\n",
    "  NEGATIVE = 'NEGATIVE'\n",
    "  POSITIVE = 'POSITIVE'\n",
    "  NEUTRAL = 'NEUTRAL'\n",
    "\n",
    "\n",
    "# Review object\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "\n",
    "    def get_sentiment(self):\n",
    "        if self.score <= 2:\n",
    "          return Sentiment.NEGATIVE\n",
    "        elif self.score == 3:\n",
    "          return Sentiment.NEUTRAL\n",
    "        else:\n",
    "          return Sentiment.POSITIVE\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'Text:\\t\\t{0}\\nScore:\\t\\t{1}\\nSentiment:\\t{2}'.format(self.text, self.score, self.sentiment)\n",
    "\n",
    "\n",
    "# Review Container\n",
    "class ReviewsContainer:\n",
    "    def __init__(self, reviews):\n",
    "        self.reviews = reviews\n",
    "\n",
    "    def get_text(self):\n",
    "        return [x.text for x in self.reviews]\n",
    "\n",
    "    def get_sentiment(self):\n",
    "        return [x.sentiment for x in self.reviews]\n",
    "\n",
    "    def evenly_distribute(self):\n",
    "        negatives = list(filter(lambda x: x.sentiment == Sentiment.NEGATIVE, self.reviews))\n",
    "        positives = list(filter(lambda x: x.sentiment == Sentiment.POSITIVE, self.reviews))\n",
    "\n",
    "        positive_shrunk = positives[:len(negatives)]\n",
    "        self.reviews = positive_shrunk + negatives\n",
    "        random.shuffle(self.reviews)\n",
    "\n",
    "        print('Positive reviews: {0}'.format(len(positive_shrunk)))\n",
    "        print('Negative reviews: {0}'.format(len(negatives)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-flour",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "tired-export",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\t\tI hoped for Mia to have some peace in this book, but her story is so real and raw.  Broken World was so touching and emotional because you go from Mia's trauma to her trying to cope.  I love the way the story displays how there is no \"just bouncing back\" from being sexually assaulted.  Mia showed us how those demons come for you every day and how sometimes they best you. I was so in the moment with Broken World and hurt with Mia because she was surrounded by people but so alone and I understood her feelings.  I found myself wishing I could give her some of my courage and strength or even just to be there for her.  Thank you Lizzy for putting a great character's voice on a strong subject and making it so that other peoples story may be heard through Mia's.\n",
      "Score:\t\t5.0\n",
      "Sentiment:\tPOSITIVE\n"
     ]
    }
   ],
   "source": [
    "data_path = 'datasets/amazon_book_data.json'\n",
    "\n",
    "# Collect reviews from the file\n",
    "reviews = []\n",
    "with open(data_path) as file:\n",
    "  for line in file:\n",
    "    review = json.loads(line)\n",
    "    reviews.append(Review(review['reviewText'], review['overall']))\n",
    "\n",
    "# Preview of a random Review\n",
    "print(reviews[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-forest",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "excess-battlefield",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training data: 6700\n",
      "Positive reviews: 436\n",
      "Negative reviews: 436\n",
      "Positive reviews: 208\n",
      "Negative reviews: 208\n"
     ]
    }
   ],
   "source": [
    "# Split data info training & testing subsets\n",
    "\n",
    "train_data, test_data = train_test_split(reviews, test_size = 0.33, random_state = 42)\n",
    "print('Length of training data: {0}'.format(len(train_data)))\n",
    "\n",
    "train_container = ReviewsContainer(train_data)\n",
    "test_container = ReviewsContainer(test_data)\n",
    "\n",
    "train_container.evenly_distribute()\n",
    "test_container.evenly_distribute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-apartment",
   "metadata": {},
   "source": [
    "## Spliting the review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sound-contributor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\t\tI haven't read the previous tales from the Clifton Chronicles so i was pleasantly suprised. The villains are picturesque, the plot is unusual and the book is vintage Jeffrey Archer. Without reading the previous editions I don't have a full picture of the legacy of the Clifton family but enjoyable reading nevertheless.\n",
      "Sentiment:\tPOSITIVE\n"
     ]
    }
   ],
   "source": [
    "train_x = train_container.get_text()\n",
    "train_y = train_container.get_sentiment()\n",
    "\n",
    "test_x = test_container.get_text()\n",
    "test_y = test_container.get_sentiment()\n",
    "\n",
    "print('Text:\\t\\t{0}\\nSentiment:\\t{1}'.format(train_x[10], train_y[10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-vermont",
   "metadata": {},
   "source": [
    "## Bags of Words Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "wicked-right",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I always look forward to Amanda Quick novels, I know it will be an afternoon spent enjoying myself.  I have read others that I found more enjoyable, ie Crystal Gardens and any of the Arcane series, but this was a good read.  I would think it an ideal read for the beach or summer leisure.\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# vectorizer = CountVectorizer()\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "test_x_vectors = vectorizer.transform(test_x)\n",
    "\n",
    "print(train_x[0])\n",
    "print(train_x_vectors[0].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-forum",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-marriage",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "guided-continent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Score: 0.8076923076923077\n"
     ]
    }
   ],
   "source": [
    "clf_svc = SVC(kernel = 'linear')\n",
    "\n",
    "clf_svc.fit(train_x_vectors, train_y)\n",
    "svc_predictions = clf_svc.predict(test_x_vectors)\n",
    "\n",
    "svc_score = clf_svc.score(test_x_vectors, test_y)\n",
    "print('SVM Score: {0}'.format(svc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-lounge",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "headed-hometown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Score: 0.6490384615384616\n"
     ]
    }
   ],
   "source": [
    "clf_dec = DecisionTreeClassifier()\n",
    "\n",
    "clf_dec.fit(train_x_vectors, train_y)\n",
    "dec_predictions = clf_dec.predict(test_x_vectors)\n",
    "\n",
    "dec_score = clf_dec.score(test_x_vectors, test_y)\n",
    "print('Decision Tree Score: {0}'.format(dec_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-replica",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "right-sacramento",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Score: 0.8052884615384616\n"
     ]
    }
   ],
   "source": [
    "clf_log = LogisticRegression()\n",
    "\n",
    "clf_log.fit(train_x_vectors, train_y)\n",
    "log_predictions = clf_log.predict(test_x_vectors)\n",
    "\n",
    "log_score = clf_log.score(test_x_vectors, test_y)\n",
    "print('Logistic Regression Score: {0}'.format(log_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-garbage",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "charged-animal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC F1 Score:\t\t\t [0.80582524 0.80952381]\n",
      "Decition Tree F1 Score:\t\t [0.64563107 0.65238095]\n",
      "Logistic Regression F1 Score:\t [0.80291971 0.80760095]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Logistic Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.649038</td>\n",
       "      <td>0.805288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Linear SVM  Decision Tree  Logistic Regression\n",
       "Mean Accuracy    0.807692       0.649038             0.805288"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating F1 Score\n",
    "svc_f1_score = f1_score(test_y, svc_predictions, average = None, labels = [Sentiment.POSITIVE, Sentiment.NEGATIVE])\n",
    "dec_f1_score = f1_score(test_y, dec_predictions, average = None, labels = [Sentiment.POSITIVE, Sentiment.NEGATIVE])\n",
    "log_f1_score = f1_score(test_y, log_predictions, average = None, labels = [Sentiment.POSITIVE, Sentiment.NEGATIVE])\n",
    "\n",
    "print('SVC F1 Score:\\t\\t\\t {0}'.format(svc_f1_score))\n",
    "print('Decition Tree F1 Score:\\t\\t {0}'.format(dec_f1_score))\n",
    "print('Logistic Regression F1 Score:\\t {0}'.format(log_f1_score))\n",
    "\n",
    "pd.DataFrame({'Linear SVM': [svc_score],\n",
    "              'Decision Tree': [dec_score],\n",
    "              'Logistic Regression': [log_score]},\n",
    "             index = ['Mean Accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-thirty",
   "metadata": {},
   "source": [
    "## Tuning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "latin-crack",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': (1, 4, 8, 16, 32), 'kernel': ('linear', 'rbf')})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'kernel': ('linear', 'rbf'),\n",
    "    'C': (1, 4, 8, 16, 32)\n",
    "}\n",
    "\n",
    "tuned_svc = SVC()\n",
    "clf = GridSearchCV(tuned_svc, parameters, cv = 5)\n",
    "clf.fit(train_x_vectors, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-separation",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "certified-moment",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('svc_sentiment_classifier_model.pckle', 'wb') as file:\n",
    "    pickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "convertible-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = None\n",
    "\n",
    "with open('svc_sentiment_classifier_model.pckle', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "artificial-mailing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The strong characters introduced in the beginning of book 1 took on a whiney, pathetic quality. The story was repetitive and drawn out unnecessarily.  The author took a strong foundation and destroyed it, I'm beyond disappointed especially because I will never know how it ends (if this author ever lets it) because I will avoid this author at all costs in the future.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_x[5])\n",
    "loaded_model.predict(test_x_vectors[5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
